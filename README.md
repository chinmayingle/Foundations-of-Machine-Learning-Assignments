Foundations of Machine Learning Assignments
This repository hosts four Jupyter notebooks corresponding to the major programming assignments for the IIT Hyderabad Foundations of Machine Learning course (Aug–Nov 2024). Each notebook implements core ML algorithms from scratch in Python, accompanied by theoretical explanations, experiments, visualizations, and performance evaluations.

Repository structure:

Assignment1_kNN_DecisionTrees_NB.ipynb
– k-nearest neighbors, decision trees, Naive Bayes classifiers
– Model selection, cross-validation, performance metrics on synthetic and UCI datasets

Assignment2_SVM_Kernels.ipynb
– Support vector machines with linear and nonlinear kernels
– Decision boundary visualizations, Gaussian, polynomial, and custom kernel experiments

Assignment3_NN_Ensembles_Regularization.ipynb
– Feedforward neural network from scratch with L1/L2 regularization and dropout
– Bagging and boosting ensembles combining trees and logistic regression

Assignment4_LogisticClustering_DIMRED.ipynb
– Logistic regression via gradient descent and Newton’s method
– K-means clustering and PCA for dimensionality reduction with visual analysis

Key highlights:

End-to-end ML pipelines: data loading, preprocessing, feature engineering, training, evaluation, and plotting

Theoretical insights: VC-dimension, convexity, regularizers, kernel tricks

Real-world datasets: UCI ML Repository, Kaggle house-price and taxi-fare data

Efficient implementations using NumPy, Matplotlib, and scikit-learn for benchmarking

Hyperparameter tuning through grid search and cross-validation

Usage instructions:

Clone this repository

Create and activate a Python 3.8+ environment

Install dependencies with pip install -r requirements.txt

Launch Jupyter Lab or Notebook and open any assignment notebook

Explore the notebooks to understand both the theory and practice of foundational machine learning algorithms, and adapt these implementations for further study or projects.
